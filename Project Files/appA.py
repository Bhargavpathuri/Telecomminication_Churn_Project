# -*- coding: utf-8 -*-
"""appA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wcS5aIOFbF-bYTT-iGfFi7ey4AM6lXzD
"""

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
from io import BytesIO
import random

# Load the dataset
data = pd.read_csv("telecommunications_churn.csv")

# Load the trained model and scaler
model = joblib.load("random_forest_model.pkl")
scaler = joblib.load("scaler.pkl")

# Add custom CSS
st.markdown(
    """
    <style>
        body {
            font-family: 'Arial', sans-serif;
            background: linear-gradient(to right, #f7f7f7, #e3f2fd);
            color: #333333;
        }
        .stButton button {
            background-color: #32CD32;
            color: white;
            border: none;
            padding: 10px 20px;
            font-size: 16px;
            border-radius: 8px;
            box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
            transition: transform 0.2s, background-color 0.3s;
        }
        .stButton button:hover {
            background-color: #ff8c66;
            transform: scale(1.05);
        }
        .stSlider {
            color: #0056b3;
        }
    </style>
    """,
    unsafe_allow_html=True,
)

# Streamlit UI
st.title("Customer Churn Prediction App")
st.write("Upload your dataset and set the threshold to predict churn probabilities.")

# File uploader
uploaded_file = st.file_uploader("Upload CSV File", type=["csv"])

if uploaded_file is not None:
    # Load the uploaded dataset
    data = pd.read_csv(uploaded_file)
    st.write("Dataset loaded successfully!")

    # Churn prediction threshold
    threshold = st.slider("Set Churn Probability Threshold", 0.1, 0.9, 0.5)

    # Predict button
    if st.button("Predict for All Rows"):
        # Prepare input data for prediction
        features = data.iloc[:, :-1]  # Assuming last column is the target
        scaled_features = scaler.transform(features)

        # Predictions
        probabilities = model.predict_proba(scaled_features)[:, 1]
        predictions = ["Likely to churn" if prob > threshold else "Unlikely to churn" for prob in probabilities]

        # Add predictions and probabilities to the dataset
        data["Churn Probability"] = probabilities
        data["Churn Prediction"] = predictions

        # Filter rows with probabilities greater than the threshold
        filtered_data = data[data["Churn Probability"] > threshold]

        # Display filtered results
        st.write(f"**Rows with Churn Probability greater than {threshold}:**")
        st.dataframe(filtered_data)

        # Downloadable CSV for filtered data
        csv = BytesIO()
        filtered_data.to_csv(csv, index=False)
        st.download_button(
            label="Download Filtered Data as CSV",
            data=csv.getvalue(),
            file_name="filtered_churn_predictions.csv",
            mime="text/csv",
        )

        # Visualization: Threshold vs Number of Rows Above Threshold
        thresholds = np.linspace(0.1, 0.9, 9)
        rows_above_threshold = [sum(probabilities > t) for t in thresholds]

        st.subheader("Visualization: Threshold vs Number of Rows")
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.plot(thresholds, rows_above_threshold, marker='o', linestyle='-', color='blue')
        ax.set_xlabel("Threshold")
        ax.set_ylabel("Number of Rows Above Threshold")
        ax.set_title("Threshold vs Number of Rows Above Threshold")
        st.pyplot(fig)

        st.success("Prediction completed for all rows!")